{
    "items": [
        {
            "tags": [
                "python",
                "numpy",
                "matrix",
                "vectorization",
                "random"
            ],
            "answers": [
                {
                    "comments": [
                        {
                            "owner": {
                                "account_id": 286681,
                                "reputation": 36360,
                                "user_id": 586086,
                                "user_type": "registered",
                                "accept_rate": 49,
                                "display_name": "Andrew Mao"
                            },
                            "edited": false,
                            "score": 0,
                            "creation_date": 1449692557,
                            "post_id": 34188190,
                            "comment_id": 56122829,
                            "link": "https://stackoverflow.com/questions/34187130/fast-random-weighted-selection-across-all-rows-of-a-stochastic-matrix/34188190#comment56122829_34188190",
                            "body": "Thanks for the answer, I think part of the reason is the inherent slowness of <code>numpy.random.choice</code> in the post I linked. But I think having a for loop in Python is still not going to be great when n=10000, for example. There has to be a better way!"
                        }
                    ],
                    "owner": {
                        "account_id": 6332,
                        "reputation": 17537,
                        "user_id": 10601,
                        "user_type": "registered",
                        "accept_rate": 91,
                        "display_name": "perimosocordiae"
                    },
                    "comment_count": 1,
                    "is_accepted": false,
                    "score": 3,
                    "last_activity_date": 1449692212,
                    "creation_date": 1449692212,
                    "answer_id": 34188190,
                    "question_id": 34187130,
                    "link": "https://stackoverflow.com/questions/34187130/fast-random-weighted-selection-across-all-rows-of-a-stochastic-matrix/34188190#34188190",
                    "body": "<p>I don't think it's possible to completely vectorize this, but you can still get a decent speedup by vectorizing as much as you can. Here's what I came up with:</p>\n\n<pre><code>def improved(prob_matrix, items):\n    # transpose here for better data locality later\n    cdf = np.cumsum(prob_matrix.T, axis=1)\n    # random numbers are expensive, so we'll get all of them at once\n    ridx = np.random.random(size=n)\n    # the one loop we can't avoid, made as simple as possible\n    idx = np.zeros(n, dtype=int)\n    for i, r in enumerate(ridx):\n      idx[i] = np.searchsorted(cdf[i], r)\n    # fancy indexing all at once is faster than indexing in a loop\n    return items[idx]\n</code></pre>\n\n<p>Testing against the version in the question:</p>\n\n<pre><code>def original(prob_matrix, items):\n    choices = np.zeros((n,))\n    # This is slow, because of the loop in Python\n    for i in range(n):\n        choices[i] = np.random.choice(items, p=prob_matrix[:,i])\n    return choices\n</code></pre>\n\n<p>Here's the speedup (using the setup code given in the question):</p>\n\n<pre><code>In [45]: %timeit original(prob_matrix, items)\n100 loops, best of 3: 2.86 ms per loop\n\nIn [46]: %timeit improved(prob_matrix, items)\nThe slowest run took 4.15 times longer than the fastest. This could mean that an intermediate result is being cached\n10000 loops, best of 3: 157 \u00b5s per loop\n</code></pre>\n\n<p>I'm not sure why there's a big discrepancy in timings for my version, but even the slowest run (~650 \u00b5s) is still almost 5x faster.</p>\n"
                },
                {
                    "comments": [
                        {
                            "owner": {
                                "account_id": 286681,
                                "reputation": 36360,
                                "user_id": 586086,
                                "user_type": "registered",
                                "accept_rate": 49,
                                "display_name": "Andrew Mao"
                            },
                            "edited": false,
                            "score": 0,
                            "creation_date": 1449700534,
                            "post_id": 34190035,
                            "comment_id": 56127011,
                            "link": "https://stackoverflow.com/questions/34187130/fast-random-weighted-selection-across-all-rows-of-a-stochastic-matrix/34190035#comment56127011_34190035",
                            "body": "Great answer! Regarding your initial comment, I don&#39;t think you can even do a vectorized <code>searchsorted</code> on a 2D array, can you? So it&#39;s going to be slow anyway."
                        },
                        {
                            "owner": {
                                "account_id": 300328,
                                "reputation": 112936,
                                "user_id": 1217358,
                                "user_type": "registered",
                                "display_name": "Warren Weckesser"
                            },
                            "reply_to_user": {
                                "account_id": 286681,
                                "reputation": 36360,
                                "user_id": 586086,
                                "user_type": "registered",
                                "accept_rate": 49,
                                "display_name": "Andrew Mao"
                            },
                            "edited": false,
                            "score": 1,
                            "creation_date": 1449700835,
                            "post_id": 34190035,
                            "comment_id": 56127151,
                            "link": "https://stackoverflow.com/questions/34187130/fast-random-weighted-selection-across-all-rows-of-a-stochastic-matrix/34190035#comment56127151_34190035",
                            "body": "I mean <code>searchsorted</code> used in a loop, as in the <code>improved</code> function.  For sufficiently large <code>m</code>, the better time complexity of the code in <code>improved</code> (even with its slow python loop) will beat the <code>vectorized</code> solution."
                        }
                    ],
                    "owner": {
                        "account_id": 300328,
                        "reputation": 112936,
                        "user_id": 1217358,
                        "user_type": "registered",
                        "display_name": "Warren Weckesser"
                    },
                    "comment_count": 2,
                    "is_accepted": true,
                    "score": 22,
                    "last_activity_date": 1449869285,
                    "last_edit_date": 1449869285,
                    "creation_date": 1449699367,
                    "answer_id": 34190035,
                    "question_id": 34187130,
                    "link": "https://stackoverflow.com/questions/34187130/fast-random-weighted-selection-across-all-rows-of-a-stochastic-matrix/34190035#34190035",
                    "body": "<p>Here's a fully vectorized version that's pretty fast:</p>\n\n<pre><code>def vectorized(prob_matrix, items):\n    s = prob_matrix.cumsum(axis=0)\n    r = np.random.rand(prob_matrix.shape[1])\n    k = (s &lt; r).sum(axis=0)\n    return items[k]\n</code></pre>\n\n<p><em>In theory</em>, <code>searchsorted</code> is the right function to use for looking up the random value in the cumulatively summed probabilities, but with <code>m</code> being relatively small, <code>k = (s &lt; r).sum(axis=0)</code> ends up being much faster.  Its time complexity is O(m), while the <code>searchsorted</code> method is O(log(m)), but that will only matter for much larger <code>m</code>.  <em>Also</em>, <code>cumsum</code> is O(m), so both <code>vectorized</code> and @perimosocordiae's <code>improved</code> are O(m).  (If your <code>m</code> is, in fact, much larger, you'll have to run some tests to see how large <code>m</code> can be before this method is slower.)</p>\n\n<p>Here's the timing I get with <code>m = 10</code> and <code>n = 10000</code> (using the functions <code>original</code> and <code>improved</code> from @perimosocordiae's answer):</p>\n\n<pre><code>In [115]: %timeit original(prob_matrix, items)\n1 loops, best of 3: 270 ms per loop\n\nIn [116]: %timeit improved(prob_matrix, items)\n10 loops, best of 3: 24.9 ms per loop\n\nIn [117]: %timeit vectorized(prob_matrix, items)\n1000 loops, best of 3: 1 ms per loop\n</code></pre>\n\n<p>The full script where the functions are defined is:</p>\n\n<pre><code>import numpy as np\n\n\ndef improved(prob_matrix, items):\n    # transpose here for better data locality later\n    cdf = np.cumsum(prob_matrix.T, axis=1)\n    # random numbers are expensive, so we'll get all of them at once\n    ridx = np.random.random(size=n)\n    # the one loop we can't avoid, made as simple as possible\n    idx = np.zeros(n, dtype=int)\n    for i, r in enumerate(ridx):\n        idx[i] = np.searchsorted(cdf[i], r)\n    # fancy indexing all at once is faster than indexing in a loop\n    return items[idx]\n\n\ndef original(prob_matrix, items):\n    choices = np.zeros((n,))\n    # This is slow, because of the loop in Python\n    for i in range(n):\n        choices[i] = np.random.choice(items, p=prob_matrix[:,i])\n    return choices\n\n\ndef vectorized(prob_matrix, items):\n    s = prob_matrix.cumsum(axis=0)\n    r = np.random.rand(prob_matrix.shape[1])\n    k = (s &lt; r).sum(axis=0)\n    return items[k]\n\n\nm = 10\nn = 10000 # Or some very large number\n\nitems = np.arange(m)\nprob_weights = np.random.rand(m, n)\nprob_matrix = prob_weights / prob_weights.sum(axis=0, keepdims=True)\n</code></pre>\n"
                }
            ],
            "owner": {
                "account_id": 286681,
                "reputation": 36360,
                "user_id": 586086,
                "user_type": "registered",
                "accept_rate": 49,
                "display_name": "Andrew Mao"
            },
            "comment_count": 0,
            "is_answered": true,
            "accepted_answer_id": 34190035,
            "answer_count": 2,
            "score": 17,
            "last_activity_date": 1449869285,
            "creation_date": 1449688498,
            "last_edit_date": 1495535455,
            "question_id": 34187130,
            "link": "https://stackoverflow.com/questions/34187130/fast-random-weighted-selection-across-all-rows-of-a-stochastic-matrix",
            "title": "Fast random weighted selection across all rows of a stochastic matrix",
            "body": "<p><code>numpy.random.choice</code> allows for weighted selection from a vector, i.e.</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>arr = numpy.array([1, 2, 3])\nweights = numpy.array([0.2, 0.5, 0.3])\nchoice = numpy.random.choice(arr, p=weights) \n</code></pre>\n\n<p>selects 1 with probability 0.2, 2 with probability 0.5, and 3 with probability 0.3.</p>\n\n<p>What if we wanted to do this quickly in a vectorized fashion for a 2D array (matrix) for which each of the rows are a vector of probabilities? That is, we want a vector of choices from a stochastic matrix? This is the super slow way:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\n\nm = 10\nn = 100 # Or some very large number\n\nitems = np.arange(m)\nprob_weights = np.random.rand(m, n)\nprob_matrix = prob_weights / prob_weights.sum(axis=0, keepdims=True)\n\nchoices = np.zeros((n,))\n# This is slow, because of the loop in Python\nfor i in range(n):\n    choices[i] = np.random.choice(items, p=prob_matrix[:,i])\n</code></pre>\n\n<p><code>print(choices)</code>:</p>\n\n<pre><code>array([ 4.,  7.,  8.,  1.,  0.,  4.,  3.,  7.,  1.,  5.,  7.,  5.,  3.,\n        1.,  9.,  1.,  1.,  5.,  9.,  8.,  2.,  3.,  2.,  6.,  4.,  3.,\n        8.,  4.,  1.,  1.,  4.,  0.,  1.,  8.,  5.,  3.,  9.,  9.,  6.,\n        5.,  4.,  8.,  4.,  2.,  4.,  0.,  3.,  1.,  2.,  5.,  9.,  3.,\n        9.,  9.,  7.,  9.,  3.,  9.,  4.,  8.,  8.,  7.,  6.,  4.,  6.,\n        7.,  9.,  5.,  0.,  6.,  1.,  3.,  3.,  2.,  4.,  7.,  0.,  6.,\n        3.,  5.,  8.,  0.,  8.,  3.,  4.,  5.,  2.,  2.,  1.,  1.,  9.,\n        9.,  4.,  3.,  3.,  2.,  8.,  0.,  6.,  1.])\n</code></pre>\n\n<p><a href=\"https://stackoverflow.com/q/24140114/586086\">This post</a> suggests that <code>cumsum</code> and <code>bisect</code> could be a potential approach, and is fast. But while <code>numpy.cumsum(arr, axis=1)</code> can do this along one axis of a numpy array, the <a href=\"https://docs.python.org/2/library/bisect.html\" rel=\"noreferrer\"><code>bisect.bisect</code></a> function only works on a single array at a time. Similarly, <a href=\"http://docs.scipy.org/doc/numpy/reference/generated/numpy.searchsorted.html\" rel=\"noreferrer\"><code>numpy.searchsorted</code></a> only works on 1D arrays as well.</p>\n\n<p>Is there a quick way to do this using only vectorized operations?</p>\n"
        }
    ],
    "has_more": false,
    "quota_max": 10000,
    "quota_remaining": 8874
}